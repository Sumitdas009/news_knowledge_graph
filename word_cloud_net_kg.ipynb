{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "import mpld3\n",
    "from newspaper import Article\n",
    "import spacy\n",
    "import neuralcoref\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "neuralcoref.add_to_pipe(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = pd.read_csv('sample_data.csv')\n",
    "article.columns = ['idx','tags','text','genre','cluster']\n",
    "article = article.head(100)\n",
    "article = article.dropna()\n",
    "article.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import three lists: titles, links and wikipedia synopses\n",
    "titles = article.tags.tolist()\n",
    "\n",
    "synopses = article.text.tolist()\n",
    "    \n",
    "genres = article.genre.tolist()\n",
    "# print (genres)\n",
    "print(str(len(titles)) + ' titles')\n",
    "print(str(len(synopses)) + ' synopses')\n",
    "print(str(len(genres)) + ' genres')\n",
    "# synopses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"titles: \", titles[0])\n",
    "text = synopses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relations(id, text):\n",
    "    print (\"Working for title: \", id)\n",
    "    text = re.sub(r'\\n+', '.', text)  # replace multiple newlines with period\n",
    "    text = re.sub(r'\\[\\d+\\]', ' ', text)  # remove reference numbers\n",
    "    text = nlp(text)\n",
    "    text = nlp(text._.coref_resolved)  # resolve coreference clusters\n",
    "    sentences = [sent.string.strip() for sent in text.sents]  # split text into sentences\n",
    "    ent_pairs = list()\n",
    "    who = set()\n",
    "    where = set()\n",
    "    when = set()\n",
    "#     sent = sentences[0]\n",
    "    for sent in sentences:\n",
    "        sent = nlp(sent)\n",
    "        #print (sent)\n",
    "        spans = list(sent.ents) + list(sent.noun_chunks)  # collect nodes\n",
    "        spans = spacy.util.filter_spans(spans)\n",
    "        with sent.retokenize() as retokenizer:\n",
    "            [retokenizer.merge(span) for span in spans]\n",
    "        for ent in sent.ents:\n",
    "            if ent.label_ == \"GPE\" and ent.text not in where:\n",
    "                where.add(ent.text)\n",
    "                ent_pairs.append({ \"title\": id, \"relation\": \"occurs at\", \"object\": ent.text })\n",
    "            elif ent.label_ == \"PERSON\" and ent.text not in who:\n",
    "                who.add(ent.text)\n",
    "                ent_pairs.append({ \"title\": id, \"relation\": \"is about\", \"object\": ent.text })\n",
    "            elif ent.label_ == \"TIME\" and ent.text not in when:\n",
    "                when.add(ent.text)\n",
    "                ent_pairs.append({ \"title\": id, \"relation\": \"at time\", \"object\": ent.text })\n",
    "            else:\n",
    "                #print (\"No match\", ent.label_, \"==>\", ent.text)\n",
    "                next\n",
    "\n",
    "        for token in sent:\n",
    "            relation = [w for w in token.ancestors if w.dep_ == 'ROOT'] \n",
    "        print (\"token\", relation)\n",
    "        if relation:\n",
    "            relation = relation[0]\n",
    "            # add adposition or particle to relationship\n",
    "            if relation.nbor(1).pos_ in ('ADP', 'PART'):  \n",
    "                relation = ' '.join((str(relation),\n",
    "                        str(relation.nbor(1))))\n",
    "        else:\n",
    "            relation = 'unknown'\n",
    "        \n",
    "    pairs = pd.DataFrame(ent_pairs, columns=['title',\n",
    "                     'relation', 'object'])\n",
    "\n",
    "    print('Entity pairs extracted:', str(len(ent_pairs)))\n",
    "    return pairs\n",
    "#         print (\"it happened at: \", where)\n",
    "#         print (\"around: \", when)\n",
    "#         print (\"with: \", who)\n",
    "#         print (\"relation\", relation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def draw_kg(pairs):\n",
    "    k_graph = nx.from_pandas_edgelist(pairs, 'title', 'object',\n",
    "            create_using=nx.MultiDiGraph())\n",
    "    node_deg = nx.degree(k_graph)\n",
    "    layout = nx.spring_layout(k_graph, k=0.15, iterations=20)\n",
    "    plt.figure(num=None, figsize=(120, 90), dpi=80)\n",
    "    nx.draw_networkx(\n",
    "        k_graph,\n",
    "        node_size=[int(deg[1]) * 500 for deg in node_deg],\n",
    "        arrowsize=20,\n",
    "        linewidths=1.5,\n",
    "        pos=layout,\n",
    "        edge_color='red',\n",
    "        edgecolors='black',\n",
    "        node_color='white',\n",
    "        )\n",
    "    labels = dict(zip(list(zip(pairs.title, pairs.object)),\n",
    "                  pairs['relation'].tolist()))\n",
    "    nx.draw_networkx_edge_labels(k_graph, pos=layout, edge_labels=labels,\n",
    "                                 font_color='red')\n",
    "    #plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_graph(pairs, node):\n",
    "    k_graph = nx.from_pandas_edgelist(pairs, 'title', 'object',\n",
    "            create_using=nx.MultiDiGraph())\n",
    "    edges = nx.dfs_successors(k_graph, node)\n",
    "    nodes = []\n",
    "    for k, v in edges.items():\n",
    "        nodes.extend([k])\n",
    "        nodes.extend(v)\n",
    "    subgraph = k_graph.subgraph(nodes)\n",
    "    layout = (nx.random_layout(k_graph))\n",
    "    nx.draw_networkx(\n",
    "        subgraph,\n",
    "        node_size=1000,\n",
    "        arrowsize=20,\n",
    "        linewidths=1.5,\n",
    "        pos=layout,\n",
    "        edge_color='red',\n",
    "        edgecolors='black',\n",
    "        node_color='white'\n",
    "        )\n",
    "    labels = dict(zip((list(zip(pairs.title, pairs.object))),\n",
    "                    pairs['relation'].tolist()))\n",
    "    edges= tuple(subgraph.out_edges(data=False))\n",
    "    sublabels ={k: labels[k] for k in edges}\n",
    "    nx.draw_networkx_edge_labels(subgraph, pos=layout, edge_labels=sublabels,\n",
    "                                font_color='red')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pairs = pd.DataFrame([], columns=['title',\n",
    "                     'relation', 'object'])\n",
    "# for index, title in enumerate(titles):\n",
    "for index in range(0,10):\n",
    "    pairs = get_relations(titles[index],synopses[index])\n",
    "    all_pairs = all_pairs.append(pairs, ignore_index = True)\n",
    "print (all_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_kg(all_pairs)\n",
    "# filter_graph(pairs, 'Congress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
